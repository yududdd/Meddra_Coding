{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "* Please note data loading, preprocessing etc are handled in other python modules. Here is a POC (proof of concept) version for model part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import importlib\n",
    "warnings.filterwarnings('ignore')\n",
    "from loader import Loader\n",
    "from preprocessor import Preprocessor\n",
    "from spliter import Spliter \n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "# file_name = [\"data/ae.sas7bdat\"]\n",
    "# dict_name = [\"data/meddra_dict_v21\",\"data/meddra_dict_v22\", \"data/meddra_dict_v23\"]\n",
    "dict_name = [\"data/meddra_dict_v22\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Loader(dict_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verbatim Term</th>\n",
       "      <th>LLT Name</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contact dermatitis</td>\n",
       "      <td>contact dermatitis</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cataracts</td>\n",
       "      <td>cataracts</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>occasional lightheadedness</td>\n",
       "      <td>lightheadedness</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>occassional neurologic dizziness</td>\n",
       "      <td>dizziness</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swollen lymph nodes bilateral neck</td>\n",
       "      <td>swollen lymph nodes</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32768</th>\n",
       "      <td>right hemicolectomy</td>\n",
       "      <td>right hemicolectomy</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32769</th>\n",
       "      <td>hepatic lobectomy</td>\n",
       "      <td>liver lobectomy</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32770</th>\n",
       "      <td>colon biopsy</td>\n",
       "      <td>colon biopsy</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32771</th>\n",
       "      <td>laparoscopic low anterior resection</td>\n",
       "      <td>lower anterior resection</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32772</th>\n",
       "      <td>cat scan guided biopsy</td>\n",
       "      <td>biopsy lung</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32773 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Verbatim Term                  LLT Name  Version\n",
       "0                       contact dermatitis        contact dermatitis     17.0\n",
       "1                                cataracts                 cataracts     17.0\n",
       "2               occasional lightheadedness           lightheadedness     17.0\n",
       "3         occassional neurologic dizziness                 dizziness     17.0\n",
       "4       swollen lymph nodes bilateral neck       swollen lymph nodes     17.0\n",
       "...                                    ...                       ...      ...\n",
       "32768                  right hemicolectomy       right hemicolectomy     23.0\n",
       "32769                    hepatic lobectomy           liver lobectomy     23.0\n",
       "32770                         colon biopsy              colon biopsy     23.0\n",
       "32771  laparoscopic low anterior resection  lower anterior resection     23.0\n",
       "32772               cat scan guided biopsy               biopsy lung     23.0\n",
       "\n",
       "[32773 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.rawdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Preprocessor(loader.rawdf, loader.dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "medra,raw = processor.pipe_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TERM</th>\n",
       "      <th>LLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contact dermatitis</td>\n",
       "      <td>contact dermatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cataract</td>\n",
       "      <td>cataracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>occasional lightheadedness</td>\n",
       "      <td>lightheadedness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>occassional neurologic dizziness</td>\n",
       "      <td>dizziness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swollen lymph node bilateral neck</td>\n",
       "      <td>swollen lymph nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32638</th>\n",
       "      <td>abdominal hysterectomy</td>\n",
       "      <td>abdominal hysterectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32639</th>\n",
       "      <td>right hemicolectomy</td>\n",
       "      <td>right hemicolectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32640</th>\n",
       "      <td>hepatic lobectomy</td>\n",
       "      <td>liver lobectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32641</th>\n",
       "      <td>colon biopsy</td>\n",
       "      <td>colon biopsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32642</th>\n",
       "      <td>cat scan guided biopsy</td>\n",
       "      <td>biopsy lung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32643 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    TERM                     LLT\n",
       "0                     contact dermatitis      contact dermatitis\n",
       "1                               cataract               cataracts\n",
       "2             occasional lightheadedness         lightheadedness\n",
       "3       occassional neurologic dizziness               dizziness\n",
       "4      swollen lymph node bilateral neck     swollen lymph nodes\n",
       "...                                  ...                     ...\n",
       "32638             abdominal hysterectomy  abdominal hysterectomy\n",
       "32639                right hemicolectomy     right hemicolectomy\n",
       "32640                  hepatic lobectomy         liver lobectomy\n",
       "32641                       colon biopsy            colon biopsy\n",
       "32642             cat scan guided biopsy             biopsy lung\n",
       "\n",
       "[32643 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test, X_ls, X_testls = Spliter(raw, medra).get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              exacerbation herpes simplex\n",
       "1           painful - l foot joint big toe\n",
       "2         high creatinine level 106 umol l\n",
       "3            absent reflex lower extremity\n",
       "4        interstitial nodular opacity lung\n",
       "                       ...                \n",
       "30026                        uti infection\n",
       "30027                     burnt right hand\n",
       "30028                       hypomagnasemia\n",
       "30029                            sore limb\n",
       "30030                   allergy penicillin\n",
       "Name: TERM, Length: 30031, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30031,), (2612,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 49s, sys: 16.6 s, total: 6min 6s\n",
      "Wall time: 6min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# WARNING: Time consuming\n",
    "word_to_index, index_to_word, word_to_vec_map = utils.read_emb_vecs('/Volumes/Yu-HD/encoder/ri-3gram-400-tsv/vocab.tsv', '/Volumes/Yu-HD/encoder/ri-3gram-400-tsv/vectors.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word embedding vector is implemented based on paper below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@article{KHATTAK2019100057,\n",
    "title = {A survey of word embeddings for clinical text},\n",
    "journal = {Journal of Biomedical Informatics: X},\n",
    "volume = {4},\n",
    "pages = {100057},\n",
    "year = {2019},\n",
    "issn = {2590-177X},\n",
    "doi = {https://doi.org/10.1016/j.yjbinx.2019.100057},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/S2590177X19300563},\n",
    "author = {Faiza Khan Khattak and Serena Jeblee and ChloÃ© Pou-Prom and Mohamed Abdalla and Christopher Meaney and Frank Rudzicz},\n",
    "keywords = {Word embeddings, Clinical data, Natural language processing},\n",
    "abstract = {Representing words as numerical vectors based on the contexts in which they appear has become the de facto method of analyzing text with machine learning. In this paper, we provide a guide for training these representations on clinical text data, using a survey of relevant research. Specifically, we discuss different types of word representations, clinical text corpora, available pre-trained clinical word vector embeddings, intrinsic and extrinsic evaluation, applications, and limitations of these approaches. This work can be used as a blueprint for clinicians and healthcare workers who may want to incorporate clinical text features in their own models and applications.}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "CLASSES=len(set(medra['LLT']))\n",
    "WINDOWS_Size=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count potential spelling errors or words cannot be found in the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for record in X_ls:\n",
    "    for i in record[0:WINDOWS_Size]:\n",
    "        if i not in word_to_vec_map:\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7752 number of individual training words NOT found in the word embedding vectors\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(cnt) + \" number of individual training words NOT found in the word embedding vectors\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 26s, sys: 1.39 s, total: 17min 27s\n",
      "Wall time: 17min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# WARNING: Time consuming cell\n",
    "from spellchecker import SpellChecker \n",
    "spell = SpellChecker()\n",
    "for record in X_ls:\n",
    "    for i in record[0:WINDOWS_Size]:\n",
    "        if i not in word_to_vec_map:\n",
    "            idx = record.index(i)\n",
    "            record[idx] = spell.correction(i)\n",
    "            \n",
    "for record in X_testls:\n",
    "    for i in record[0:WINDOWS_Size]:\n",
    "        if i not in word_to_vec_map:\n",
    "            idx = record.index(i)\n",
    "            record[idx] = spell.correction(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt2 = 0\n",
    "for record in X_ls:\n",
    "    for i in record[0:WINDOWS_Size]:\n",
    "        if i not in word_to_vec_map:\n",
    "#             print(i)\n",
    "            cnt2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5501 number of individual training words NOT found after spell correction and other corrections\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(cnt2) + \" number of individual training words NOT found after spell correction and other corrections\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of codes is designed for first time construt encoder and decoder\n",
    "# please note the dictionary order is random, which means model and decoder should be 1-1.\n",
    "\n",
    "\n",
    "# encoder = {}\n",
    "# for i, pt in enumerate(set(medra['LLT'])):\n",
    "#     encoder.update({pt: i})\n",
    "#     i = i + 1\n",
    "# decoder = dict([(pt, i) for i, pt in encoder.items()])\n",
    "\n",
    "# outfile = open(os.path.join('data', 'lltcoder.pkl'),'wb')\n",
    "# pickle.dump(encoder,outfile)\n",
    "# outfile.close()\n",
    "# outfile = open(os.path.join('data', 'lltdecoder.pkl'),'wb')\n",
    "# pickle.dump(decoder,outfile)\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Yu-HD/Encoder/ENCODER_ML'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = pickle.load( open( \"/Volumes/Yu-HD/Encoder/ENCODER_ML/data/lltcoder.pkl\", \"rb\" ) )\n",
    "decoder = pickle.load( open( \"/Volumes/Yu-HD/Encoder/ENCODER_ML/data/lltdecoder.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code are designed to test if there are any train/test not in the target meddra version. Even though, using different version to train the model, it not makes sense to includes every version in the output since the output is version specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra in test:  []\n"
     ]
    }
   ],
   "source": [
    "print(\"extra in test: \",[i for i in set(Y_test.tolist()) if i not in set(medra['LLT'].tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: This cell takes long time\n",
    "# print(\"extra in train: \",[i for i in set(Y_train.tolist()) if i not in set(medra['LLT'].tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =np.array([[encoder[i]] for i in Y_train])\n",
    "y_test = np.array([[encoder[i]] for i in Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=len(max(X_ls,key=len))\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30031,), (30031, 1), (2612,), (2612, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emdlayer(window, textlst, dim):\n",
    "    '''generate embedding layer\n",
    "    random normal distribution from 0 to 0.01.\n",
    "    '''\n",
    "    v_tmp=[np.array([word_to_vec_map[i] \n",
    "                     if i in word_to_vec_map \n",
    "                     else (np.random.randn(dim,)*10000).astype('float32') for i in record[0:window]])\n",
    "           for record in textlst]\n",
    "    \n",
    "\n",
    "    vec = []\n",
    "    \n",
    "    for i in range(len(textlst)):\n",
    "        x1 = (np.random.randn(window-v_tmp[i].shape[0], dim)*10000).astype('float32')\n",
    "        x2 = v_tmp[i]\n",
    "        x = np.concatenate((x1,x2), axis=0)\n",
    "        vec.append(x)\n",
    "    \n",
    "    vec = np.array(vec)\n",
    "#     vec = np.array([np.concatenate((v_tmp[i],\n",
    "#                                     (np.random.randn(window-v_tmp[i].shape[0], dim)*10000).astype('float32')),\n",
    "#                                    axis=0)\n",
    "#         for i in range(len(textlst))])\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation of the input X_ls\n",
    "\n",
    "X_ls_perm = []\n",
    "\n",
    "for x in X_ls:\n",
    "    X_ls_perm.append(np.random.permutation(x).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ls_all = [*X_ls, *X_ls_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.concatenate((y_train, y_train), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.94 s, sys: 1.15 s, total: 5.09 s\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# WARNING: Time consuming Cell\n",
    "# X=emdlayer(WINDOWS_Size, X_ls, 400)\n",
    "# X=emdlayer(WINDOWS_Size, X_ls_perm, 400)\n",
    "X=emdlayer(WINDOWS_Size, X_ls_all, 400)\n",
    "Xtest=emdlayer(WINDOWS_Size, X_testls, 400)\n",
    "INPUT_DIM = X.shape[2]\n",
    "SINGLE_ATTENTION_VECTOR = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60062, 6, 400), (30031, 1), (2612, 6, 400), (2612, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y_train.shape, Xtest.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.layers import concatenate, Bidirectional, Dropout, MaxPooling1D, Conv1D\n",
    "from keras.layers.core import *\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=utils.callback_()\n",
    "filename = str('./model.demo')\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import manual_variable_initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None):\n",
    "\n",
    "    print('----- activations -----')\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
    "    funcs = [K.function([inp] + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "    layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "    return activations\n",
    "\n",
    "def attention_3d_block(inputs):\n",
    "#     inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, WINDOWS_Size))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(WINDOWS_Size, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    \n",
    "    output_attention_mul = concatenate([inputs, a_probs], name='attention_mul')\n",
    "    return output_attention_mul\n",
    "\n",
    "\n",
    "\n",
    "def model_attention_applied_after_lstm():\n",
    "    inputs = Input(shape=(WINDOWS_Size, INPUT_DIM,))\n",
    "    drop=Dropout(0.5)(inputs)\n",
    "    lstm_units1 = 128\n",
    "    lstm_out, state_h, state_c = LSTM(lstm_units1, return_sequences=True, return_state=True, recurrent_regularizer=regularizers.l2(0.01))(drop)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    decoder_out = LSTM(lstm_units1, return_sequences=True, recurrent_regularizer=regularizers.l2(0.01))(lstm_out, initial_state = encoder_states)\n",
    "    attention_mul = attention_3d_block(decoder_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(CLASSES, activation='softmax')(attention_mul)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 6, 400)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 6, 400)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 6, 128), (No 270848      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 6, 128)       131584      lstm[0][0]                       \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 128, 6)       0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128, 6)       0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 6)       42          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 6, 128)       0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention_mul (Concatenate)     (None, 6, 256)       0           lstm_1[0][0]                     \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1536)         0           attention_mul[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 79719)        122528103   flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 122,930,577\n",
      "Trainable params: 122,930,577\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "470/470 [==============================] - 538s 1s/step - loss: 9.6909 - accuracy: 0.0178 - val_loss: 8.4875 - val_accuracy: 0.0911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "470/470 [==============================] - 522s 1s/step - loss: 7.8343 - accuracy: 0.0880 - val_loss: 7.6051 - val_accuracy: 0.1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "470/470 [==============================] - 523s 1s/step - loss: 6.9420 - accuracy: 0.1515 - val_loss: 7.1547 - val_accuracy: 0.2121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "470/470 [==============================] - 521s 1s/step - loss: 6.3009 - accuracy: 0.1981 - val_loss: 6.7548 - val_accuracy: 0.2270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "470/470 [==============================] - 519s 1s/step - loss: 5.6732 - accuracy: 0.2430 - val_loss: 6.3850 - val_accuracy: 0.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "470/470 [==============================] - 517s 1s/step - loss: 5.0600 - accuracy: 0.2877 - val_loss: 6.1426 - val_accuracy: 0.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "470/470 [==============================] - 519s 1s/step - loss: 4.5653 - accuracy: 0.3312 - val_loss: 5.9198 - val_accuracy: 0.3174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "470/470 [==============================] - 516s 1s/step - loss: 4.1172 - accuracy: 0.3681 - val_loss: 5.7000 - val_accuracy: 0.3281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "470/470 [==============================] - 514s 1s/step - loss: 3.7461 - accuracy: 0.3985 - val_loss: 5.5868 - val_accuracy: 0.3434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "470/470 [==============================] - 517s 1s/step - loss: 3.3901 - accuracy: 0.4350 - val_loss: 5.4770 - val_accuracy: 0.3564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "470/470 [==============================] - 512s 1s/step - loss: 3.1183 - accuracy: 0.4625 - val_loss: 5.3336 - val_accuracy: 0.3694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "470/470 [==============================] - 515s 1s/step - loss: 2.8758 - accuracy: 0.4847 - val_loss: 5.2435 - val_accuracy: 0.3863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "470/470 [==============================] - 513s 1s/step - loss: 2.6606 - accuracy: 0.5103 - val_loss: 5.1905 - val_accuracy: 0.3832\n",
      "Epoch 14/20\n",
      "470/470 [==============================] - 515s 1s/step - loss: 2.4643 - accuracy: 0.5322 - val_loss: 5.2247 - val_accuracy: 0.3962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "470/470 [==============================] - 510s 1s/step - loss: 2.2971 - accuracy: 0.5559 - val_loss: 5.1908 - val_accuracy: 0.3940\n",
      "Epoch 16/20\n",
      "470/470 [==============================] - 530s 1s/step - loss: 2.1509 - accuracy: 0.5737 - val_loss: 5.1339 - val_accuracy: 0.4005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "470/470 [==============================] - 511s 1s/step - loss: 2.0261 - accuracy: 0.5894 - val_loss: 5.1628 - val_accuracy: 0.4058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "470/470 [==============================] - 511s 1s/step - loss: 1.9051 - accuracy: 0.6096 - val_loss: 5.1618 - val_accuracy: 0.4054\n",
      "Epoch 19/20\n",
      "470/470 [==============================] - 525s 1s/step - loss: 1.8072 - accuracy: 0.6214 - val_loss: 5.1364 - val_accuracy: 0.4177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model.demo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "470/470 [==============================] - 513s 1s/step - loss: 1.7380 - accuracy: 0.6320 - val_loss: 5.1729 - val_accuracy: 0.4074\n",
      "CPU times: user 20h 13s, sys: 8h 6min 47s, total: 1d 4h 7min 1s\n",
      "Wall time: 2h 57min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from keras import optimizers\n",
    "m0 = model_attention_applied_after_lstm()\n",
    "rms = RMSprop(lr=0.001)\n",
    "m0.compile(optimizer=rms, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "m0.summary()\n",
    "h0=m0.fit([X], y_train_all, epochs=20, batch_size=128, validation_data=([Xtest], y_test), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model stops converging after 16-17 epoch, the demo parameter to tune here is the units in lstm cell.  The the model becomes overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = m0.predict(Xtest)\n",
    "\n",
    "####obtain LLT and decode in to the dictionary term \n",
    "y_pred = [decoder[i] for i in y_p.argmax(axis=1)]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test.tolist(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotresult(hist, title, outputfile):\n",
    "\tacc = hist.history['accuracy']\n",
    "\tval_acc = hist.history['val_accuracy']\n",
    "\n",
    "\tepochs = len(acc)\n",
    "\tplt.plot(range(epochs), acc, marker='.', label='acc')\n",
    "\tplt.plot(range(epochs), val_acc, marker='.', label='val_acc')\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.grid()\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.ylabel('acc')\n",
    "\tplt.title('Training/Validation: '+ title)\n",
    "\tplt.savefig('../images/'+outputfile)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotresult(h0, '400D + LSTM Enocder/Decoder + Attention', 'm0_model_attention_applied_after_lstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Test AE Term \":X_test, \"Predicted AE LLT\": y_pred, \"Actual AE LLT\": Y_test}\n",
    "s = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1064"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s.loc[s[\"Predicted AE LLT\"] == s[\"Actual AE LLT\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test AE Term</th>\n",
       "      <th>Predicted AE LLT</th>\n",
       "      <th>Actual AE LLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>fracture t12</td>\n",
       "      <td>fractured vertebra</td>\n",
       "      <td>fractured vertebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>chronic right leg swelling</td>\n",
       "      <td>swelling legs</td>\n",
       "      <td>swelling legs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>infection cyst r cheek</td>\n",
       "      <td>cyst</td>\n",
       "      <td>cyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29822</th>\n",
       "      <td>vision blurry</td>\n",
       "      <td>blurry vision</td>\n",
       "      <td>blurry vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663</th>\n",
       "      <td>insopmia</td>\n",
       "      <td>insomnia</td>\n",
       "      <td>insomnia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19519</th>\n",
       "      <td>excessive sweating</td>\n",
       "      <td>excess sweating</td>\n",
       "      <td>excess sweating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>increase weight</td>\n",
       "      <td>weight increase</td>\n",
       "      <td>weight increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>pain toe</td>\n",
       "      <td>pain toe</td>\n",
       "      <td>pain toe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15353</th>\n",
       "      <td>ache left side chest wall</td>\n",
       "      <td>chest wall pain</td>\n",
       "      <td>chest wall pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28952</th>\n",
       "      <td>proteinuria 30</td>\n",
       "      <td>proteinuria</td>\n",
       "      <td>proteinuria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Test AE Term     Predicted AE LLT       Actual AE LLT\n",
       "6757                 fracture t12  fractured vertebra  fractured vertebra\n",
       "369    chronic right leg swelling       swelling legs       swelling legs\n",
       "3876       infection cyst r cheek                cyst                cyst\n",
       "29822               vision blurry       blurry vision       blurry vision\n",
       "19663                    insopmia            insomnia            insomnia\n",
       "...                           ...                 ...                 ...\n",
       "19519          excessive sweating     excess sweating     excess sweating\n",
       "7488              increase weight     weight increase     weight increase\n",
       "9287                     pain toe            pain toe            pain toe\n",
       "15353   ache left side chest wall     chest wall pain     chest wall pain\n",
       "28952              proteinuria 30         proteinuria         proteinuria\n",
       "\n",
       "[1064 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc[s[\"Predicted AE LLT\"] == s[\"Actual AE LLT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test AE Term</th>\n",
       "      <th>Predicted AE LLT</th>\n",
       "      <th>Actual AE LLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19076</th>\n",
       "      <td>neonatal enteral feeding intollerance</td>\n",
       "      <td>feeding intolerance</td>\n",
       "      <td>enteral feeding intolerance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27702</th>\n",
       "      <td>internal iliac vein right left</td>\n",
       "      <td>iliac vein thrombosis</td>\n",
       "      <td>vein disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30389</th>\n",
       "      <td>chronic hypertrophy pansinusitis</td>\n",
       "      <td>knee arthritis</td>\n",
       "      <td>chronic sinusitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>atrial arrhythmia</td>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>atrial arrhythmia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8094</th>\n",
       "      <td>left groin sensation mass swelling</td>\n",
       "      <td>ankle swelling</td>\n",
       "      <td>groin swelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28925</th>\n",
       "      <td>pressure sore</td>\n",
       "      <td>canker sore lip</td>\n",
       "      <td>pressure sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20831</th>\n",
       "      <td>deep venous thrombosis lower left limb</td>\n",
       "      <td>deep vein thrombosis leg</td>\n",
       "      <td>left deep vein thrombosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23721</th>\n",
       "      <td>chronic pain syndrome grade 2</td>\n",
       "      <td>catheter site pain</td>\n",
       "      <td>chronic pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19505</th>\n",
       "      <td>exacerbation anxiety secondary depression</td>\n",
       "      <td>anxiety aggravated</td>\n",
       "      <td>exacerbation anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>gaster pain</td>\n",
       "      <td>pain lower extremities</td>\n",
       "      <td>gastric pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Test AE Term           Predicted AE LLT  \\\n",
       "19076      neonatal enteral feeding intollerance       feeding intolerance   \n",
       "27702             internal iliac vein right left     iliac vein thrombosis   \n",
       "30389           chronic hypertrophy pansinusitis            knee arthritis   \n",
       "573                            atrial arrhythmia                arrhythmia   \n",
       "8094          left groin sensation mass swelling            ankle swelling   \n",
       "...                                          ...                       ...   \n",
       "28925                              pressure sore           canker sore lip   \n",
       "20831     deep venous thrombosis lower left limb  deep vein thrombosis leg   \n",
       "23721              chronic pain syndrome grade 2        catheter site pain   \n",
       "19505  exacerbation anxiety secondary depression        anxiety aggravated   \n",
       "1719                                 gaster pain    pain lower extremities   \n",
       "\n",
       "                     Actual AE LLT  \n",
       "19076  enteral feeding intolerance  \n",
       "27702                vein disorder  \n",
       "30389            chronic sinusitis  \n",
       "573              atrial arrhythmia  \n",
       "8094                groin swelling  \n",
       "...                            ...  \n",
       "28925                pressure sore  \n",
       "20831    left deep vein thrombosis  \n",
       "23721                 chronic pain  \n",
       "19505         exacerbation anxiety  \n",
       "1719                  gastric pain  \n",
       "\n",
       "[1548 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "s.loc[s[\"Predicted AE LLT\"] != s[\"Actual AE LLT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del m0\n",
    "# m0.save('my_model-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "model = load_model('./model.demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_excel('/Volumes/Yu-HD/Encoder/ENCODER_ML/data/onco-AE_coding_MedDRA v22.0_KL Review_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = test[['Verbatim Term', 'LLT Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def string_processor(x, grammer):\n",
    "        \"\"\"\n",
    "        Method to preprocess the string, includes following process:\n",
    "        1. lower case\n",
    "        2. remove punctuation\n",
    "        3. remove stop words\n",
    "        4. stem or lemmatize the word: i.e. for grammatical reasons, d documents are going to use different forms of a\n",
    "        word, such as organize, organizes, and organizing.\n",
    "        For the difference between lemmatization and stemming,\n",
    "        https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/\n",
    "        :param grammer: \"stem\" or \"lemma\"\n",
    "        :return: return a cleaned version of string (particularly the term in raw datasets, i.e. AETERM in AE)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            nltk.data.find('corpora/stopwords')\n",
    "            nltk.data.find('wordnet')\n",
    "        except LookupError:\n",
    "            # If it does not exist, the program downloads the stopwords.\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "            nltk.download(\"wordnet\", quiet=True)\n",
    "            nltk.download('stopwords', download_dir='nltk_packages', quiet=True)\n",
    "            \n",
    "        sw = stopwords.words('english')\n",
    "        # Stemming\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        # lemmatization\n",
    "        lemma = WordNetLemmatizer()\n",
    "\n",
    "        if grammer == 'stem':\n",
    "            x_cln = ' '.join([stemmer.stem(i) for i in re.sub(r'[^a-zA-Z]',' ', x).split() if i not in sw]).lower()\n",
    "        elif grammer == 'lemma':\n",
    "            x_cln = ' '.join([lemma.lemmatize(i) for i in re.sub(r'[^a-zA-Z0-9-]',' ', x).split() if i not in sw]).lower()\n",
    "        elif grammer == \"medra\":\n",
    "            x_cln = ' '.join([i.strip() for i in re.sub(r'[^a-zA-Z0-9-]',' ', x).split() if i not in sw]).lower() # keep the hyphen and numbers for the medra dictionary\n",
    "            # x_cln = ' '.join([i.strip() for i in re.sub(r'[^a-zA-Z]',' ', x).split() if i not in sw]).lower())\n",
    "        else:\n",
    "            # x_cln = ' '.join([i.strip() for i in re.sub(r'[^\\w\\s]+',' ', x).split() if i not in sw]).lower()\n",
    "            x_cln = ' '.join([i.strip() for i in re.sub(r'[^a-zA-Z0-9-]',' ', x).split() if i not in sw]).lower()\n",
    "        return x_cln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Verbatim Term'] = test['Verbatim Term'].apply(lambda x: string_processor(x, \"lemma\"))\n",
    "test['LLT Name'] = test['LLT Name'].apply(lambda x: string_processor(x, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup = test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testls_new = [w.split() for w in test['Verbatim Term']]\n",
    "len(X_testls_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOWS_Size=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt3 = 0\n",
    "WINDOWS_Size=6\n",
    "for record in X_testls_new:\n",
    "    for i in record[0:WINDOWS_Size]:\n",
    "        if i not in word_to_vec_map:\n",
    "            cnt3 += 1\n",
    "cnt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_new=emdlayer(WINDOWS_Size, X_testls_new, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_test = model.predict(Xtest_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = [decoder[i] for i in y_p_test.argmax(axis=1)]\n",
    "data0 = {\"Test AE Term \": test['Verbatim Term'], \"Predicted AE LLT\": y_pred_test, \"Actual AE LLT\": test['LLT Name']}\n",
    "s_0 = pd.DataFrame(data0)\n",
    "s0 = s_0.loc[s_0[\"Predicted AE LLT\"] == s_0[\"Actual AE LLT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test AE Term</th>\n",
       "      <th>Predicted AE LLT</th>\n",
       "      <th>Actual AE LLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bilateral le localized edema</td>\n",
       "      <td>edema lower extremities</td>\n",
       "      <td>edema lower extremities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abdominal bloating</td>\n",
       "      <td>abdominal bloating</td>\n",
       "      <td>abdominal bloating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abdominal discomfort</td>\n",
       "      <td>abdominal discomfort</td>\n",
       "      <td>abdominal discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abdominal distension discomfort due to constip...</td>\n",
       "      <td>constipation</td>\n",
       "      <td>constipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abdominal distention</td>\n",
       "      <td>abdominal distension</td>\n",
       "      <td>abdominal distension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>other diplopia</td>\n",
       "      <td>diplopia</td>\n",
       "      <td>diplopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>thromboembolic event pulmonary embolism</td>\n",
       "      <td>pulmonary embolism</td>\n",
       "      <td>pulmonary embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>vomiting intermittent</td>\n",
       "      <td>vomiting</td>\n",
       "      <td>vomiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>wbc decreased</td>\n",
       "      <td>wbc decreased</td>\n",
       "      <td>wbc decreased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Test AE Term   \\\n",
       "2                          bilateral le localized edema   \n",
       "11                                   abdominal bloating   \n",
       "12                                 abdominal discomfort   \n",
       "15    abdominal distension discomfort due to constip...   \n",
       "16                                 abdominal distention   \n",
       "...                                                 ...   \n",
       "1288                                     other diplopia   \n",
       "1296                                          pneumonia   \n",
       "1307            thromboembolic event pulmonary embolism   \n",
       "1311                              vomiting intermittent   \n",
       "1312                                      wbc decreased   \n",
       "\n",
       "             Predicted AE LLT            Actual AE LLT  \n",
       "2     edema lower extremities  edema lower extremities  \n",
       "11         abdominal bloating       abdominal bloating  \n",
       "12       abdominal discomfort     abdominal discomfort  \n",
       "15               constipation             constipation  \n",
       "16       abdominal distension     abdominal distension  \n",
       "...                       ...                      ...  \n",
       "1288                 diplopia                 diplopia  \n",
       "1296                pneumonia                pneumonia  \n",
       "1307       pulmonary embolism       pulmonary embolism  \n",
       "1311                 vomiting                 vomiting  \n",
       "1312            wbc decreased            wbc decreased  \n",
       "\n",
       "[534 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4067022086824067"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc0 = len(s0)/len(test)\n",
    "acc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
